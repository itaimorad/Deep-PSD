{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fjKaJlJymMppHOZZsuFdGSvAZpswf2_X","timestamp":1694956579466}],"toc_visible":true,"authorship_tag":"ABX9TyPuVlpvLn8aDhLoqsS0n16N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"e1P2-t50kJr7"},"outputs":[],"source":["import torch.optim.lr_scheduler as lr_scheduler\n","\n","class Model_Trigger_Classification(nn.Module):\n","  def __init__(self,dim=WL_trigger):\n","    super().__init__()\n","    self.fc1 = nn.Linear(WL_trigger,model_NP_layer1)\n","    self.fc2 = nn.Linear(model_NP_layer1,model_NP_layer2)\n","    self.fc3 = nn.Linear(model_NP_layer2,model_NP_layer3)\n","    self.fc4 = nn.Linear(model_NP_layer3,model_NP_layer4)\n","    self.fc5 = nn.Linear(model_NP_layer4,model_NP_layer5)\n","  def forward(self,x):\n","\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","    x = self.fc3(x)\n","    x = F.relu(x)\n","    x = self.fc4(x)\n","    x = F.relu(x)\n","    x = self.fc5(x)\n","\n","    return x\n","\n","def train_Model_Trigger_Classification(model,train_data,train_labels,val_data,val_labels,learning_rate,batch_size,epochs, patience=15, factor=0.2):\n","\n","  flag_start_again = 0\n","  while(flag_start_again != 2):\n","    flag_start_again = 0\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=patience, factor=factor, verbose=True)\n","\n","    losses, epoch_lst, train_accs, val_accs  = [], [] ,[], []\n","    length_train = np.shape(train_data)[0]\n","    length_val = np.shape(val_data)[0]\n","\n","    best_val_acc = 0\n","    tj = 0\n","    flagy = 0\n","    for j in range(epochs):\n","        if flagy == 1 or flag_start_again == 1:\n","          break\n","\n","        perm = np.random.permutation(length_train)\n","        train_data = train_data[perm]\n","        train_labels = train_labels[perm]\n","\n","        for i in range(0, length_train, batch_size):\n","            if (i + batch_size) > length_train:\n","                break\n","            y_in = train_data[i:i+batch_size,:]\n","            labels_in = train_labels[i:i+batch_size]\n","            y_in = torch.Tensor(y_in)\n","            labels_in = torch.Tensor(labels_in)\n","            labels_in = labels_in.long()\n","\n","            output = model(y_in)\n","            loss = criterion(output, labels_in)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if i % int(batch_size*200) == 0:\n","              losses.append(float(loss)/batch_size)  # compute *average* loss\n","              epoch_lst.append(tj)\n","              train_cost = float(loss.detach().numpy())\n","              train_acc = estimate_accuracy_Model_Trigger_Classification(model, train_data, train_labels)\n","              val_acc = estimate_accuracy_Model_Trigger_Classification(model, val_data, val_labels)\n","              train_accs.append(train_acc)\n","              val_accs.append(val_acc)\n","              print(\"Epoch %d. [Val Acc %.2f%% ] [Train Acc %.2f%%, Loss %f]\" % (\n","                    tj, val_acc, train_acc, train_cost))\n","              tj += 1\n","\n","              scheduler.step(val_acc)\n","              for param_group in optimizer.param_groups:\n","                  curr_lr = param_group['lr']\n","              if curr_lr == learning_rate*np.power(factor,3):\n","                  print(\"Training stopped. No improvement in validation accuracy for %d epochs.\" % patience)\n","                  flagy = 1\n","                  flag_start_again = 2\n","                  break\n","\n","              if tj == 10 and val_acc < 51:\n","                flag_start_again = 1\n","\n","  del y_in\n","  del labels_in\n","  return losses, epoch_lst, train_accs, val_accs\n","\n","def estimate_accuracy_Model_Trigger_Classification(model, data, labels):\n","    data = torch.Tensor(data)\n","    out = model(data)\n","    out = out.detach().numpy()\n","    pred = np.argmax(out, axis=1)\n","    num_errors = np.sum(pred != labels)\n","    num_real = np.sum(labels)\n","\n","    accuracy = 100 * ((num_real - num_errors) / num_real)\n","    return accuracy\n","\n","def run_Model_Trigger_Classification(labels_train,data_train,labels_val,data_val,labels_test,data_test,path1, path2, learning_rate=1e-3, batch_size=50, epochs=100):\n","  model = Model_Trigger_Classification()\n","\n","  mu, sigma = find_normal_parameters(data_train)\n","  norm_train,norm_val,norm_test = normalize_datasets(data_train,data_val,data_test,mu,sigma)\n","\n","  learning_curve_info = train_Model_Trigger_Classification(model,norm_train\n","                                                   , labels_train, norm_val\n","                                                   , labels_val, learning_rate, batch_size, epochs)\n","\n","  plot_learning_curve(*learning_curve_info)\n","  test_accuracy = estimate_accuracy_Model_Trigger_Classification(model, norm_test, labels_test)\n","  print(\"[Test Acc %.2f%%]\" % (test_accuracy))\n","\n","  torch.save(model, path1)\n","  np.save(path2,np.array([mu,sigma,learning_rate,batch_size,epochs]))\n","  return\n","\n","class Model_Arrival_Times_3(nn.Module):\n","  def __init__(self,dim=(WL_trigger)):\n","    super().__init__()\n","    self.fc1 = nn.Linear(WL_trigger,model_NP_layer1)\n","    self.fc2 = nn.Linear(model_NP_layer1,model_NP_layer2)\n","    self.fc3 = nn.Linear(model_NP_layer2,model_NP_layer3)\n","    self.fc4 = nn.Linear(model_NP_layer3,model_NP_layer4)\n","    self.fc5 = nn.Linear(model_NP_layer4,model_P3_layer5)\n","\n","  def forward(self,x):\n","\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","    x = self.fc3(x)\n","    x = F.relu(x)\n","    x = self.fc4(x)\n","    x = F.relu(x)\n","    x = self.fc5(x)\n","    x = F.sigmoid(x)\n","    x = WL_trigger_middle*x\n","\n","    return x\n","\n","def train_Model_Arrival_Times_3(model,train_data,train_labels,val_data,val_labels,learning_rate,batch_size,epochs, patience=15, factor=0.2):\n","\n","  flag_start_again = 0\n","  while(flag_start_again != 2):\n","    flag_start_again = 0\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    loss_func = torch.nn.L1Loss()\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=patience, factor=factor, verbose=True)\n","\n","    losses, epoch_lst, train_accs, val_accs  = [], [] ,[], []\n","    length_train = np.shape(train_data)[0]\n","    length_val = np.shape(val_data)[0]\n","\n","    best_val_acc = 0\n","    flagy = 0\n","    for j in range(epochs):\n","        if flagy == 1 or flag_start_again == 1:\n","          break\n","\n","        perm = np.random.permutation(length_train)\n","        train_data = train_data[perm]\n","        train_labels = train_labels[perm]\n","\n","        for i in range(0, length_train, batch_size):\n","            if (i + batch_size) > length_train:\n","                break\n","            y_in = train_data[i:i+batch_size,:]\n","            labels_in = train_labels[i:i+batch_size,:]\n","            y_in = torch.Tensor(y_in)\n","            labels_in = torch.Tensor(labels_in).long()\n","            labels_in = labels_in.float()\n","\n","            output = model(y_in)\n","            loss = loss_func(output, labels_in)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        losses.append(float(loss)/batch_size)  # compute *average* loss\n","        epoch_lst.append(j)\n","        train_cost = float(loss.detach().numpy())\n","        train_dist = estimate_avg_dist_Model_Arrival_Times_3(model, train_data, train_labels)\n","        val_dist = estimate_avg_dist_Model_Arrival_Times_3(model, val_data, val_labels)\n","        train_acc = accuracy_of_Model_Arrival_Times_3(model, train_data, train_labels)\n","        val_acc = accuracy_of_Model_Arrival_Times_3(model, val_data, val_labels)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        print(\"Epoch %d. [Val Avg Dist %.2f%%] [Train Avg Dist %.2f%%] [Val Acc %.2f%% ] [Train Acc %.2f%%, Loss %f]\" % (\n","        j, val_dist, train_dist, val_acc, train_acc, train_cost))\n","\n","        scheduler.step(val_acc)\n","        for param_group in optimizer.param_groups:\n","            curr_lr = param_group['lr']\n","        if curr_lr == learning_rate*np.power(factor,3):\n","            flag_start_again = 2\n","            print(\"Training stopped. No improvement in validation accuracy for %d epochs.\" % patience)\n","            flagy = 1\n","            break\n","\n","        print(val_acc)\n","        if j == 10 and val_acc < 30:\n","          flag_start_again = 1\n","\n","  del y_in\n","  del labels_in\n","  return losses, epoch_lst, train_accs, val_accs\n","\n","def accuracy_of_Model_Arrival_Times_3(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    success_mask = abs_diff < success_marg\n","    success = success_mask.sum().item()\n","    all = success_mask.numel()\n","\n","    return 100 * success / all\n","\n","def distance_histogram_3(model, data, labels):\n","\n","  num = WL_trigger_middle\n","  distance_lst = np.zeros(num)\n","  count_lst = np.zeros(num)\n","  for i in range(np.shape(data)[0]):\n","    # get a batch of data\n","    y_in = data[i,:]\n","    labels_in = labels[i,:]\n","    y_in = torch.Tensor(y_in)\n","    out = model(y_in)\n","    distance_lst[int(labels_in[0])] += abs(out[0] - labels_in[0])\n","    count_lst[int(labels_in[0])] += 1\n","    distance_lst[int(labels_in[1])] += abs(out[1] - labels_in[1])\n","    count_lst[int(labels_in[1])] += 1\n","    distance_lst[int(labels_in[2])] += abs(out[2] - labels_in[2])\n","    count_lst[int(labels_in[2])] += 1\n","  for j in range(num):\n","    if count_lst[j] == 0:\n","      count_lst[j] = 1\n","  pyplot.figure()\n","  pyplot.scatter(np.arange(num),(distance_lst/count_lst))\n","  pyplot.show()\n","\n","\n","def estimate_avg_dist_Model_Arrival_Times_3(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    avg_dist = abs_diff.sum(dim=1).mean().item()\n","\n","    return avg_dist\n","\n","def run_Model_Arrival_Times_3(labels_train,data_train,labels_val,data_val,labels_test,data_test,path1,path2, learning_rate=1e-3, batch_size=50, epochs=100):\n","  model = Model_Arrival_Times_3()\n","\n","  mu, sigma = find_normal_parameters(data_train)\n","  norm_train,norm_val,norm_test = normalize_datasets(data_train,data_val,data_test,mu,sigma)\n","\n","  learning_curve_info = train_Model_Arrival_Times_3(model,norm_train\n","                                                   , labels_train, norm_val\n","                                                   , labels_val, learning_rate, batch_size, epochs)\n","\n","  plot_learning_curve(*learning_curve_info)\n","  test_accuracy = accuracy_of_Model_Arrival_Times_3(model, norm_test, labels_test)\n","  print(\"[Test Acc %.2f%%]\" % (test_accuracy))\n","\n","  torch.save(model, path1)\n","  np.save(path2,np.array([mu,sigma,learning_rate,batch_size,epochs]))\n","  return\n","\n","class Model_Arrival_Times_2(nn.Module):\n","  def __init__(self,dim=(WL_trigger)):\n","    super().__init__()\n","    self.fc1 = nn.Linear(WL_trigger,model_NP_layer1)\n","    self.fc2 = nn.Linear(model_NP_layer1,model_NP_layer2)\n","    self.fc3 = nn.Linear(model_NP_layer2,model_NP_layer3)\n","    self.fc4 = nn.Linear(model_NP_layer3,model_NP_layer4)\n","    self.fc5 = nn.Linear(model_NP_layer4,model_P2_layer5)\n","    self.fc6 = nn.Linear(model_P2_layer5,model_P2_layer6)\n","\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","    x = self.fc3(x)\n","    x = F.relu(x)\n","    x = self.fc4(x)\n","    x = F.relu(x)\n","    x = self.fc5(x)\n","    x = F.relu(x)\n","    x = self.fc6(x)\n","    x = F.sigmoid(x)\n","    x = WL_trigger_middle*x\n","\n","    return x\n","\n","def train_Model_Arrival_Times_2(model,train_data,train_labels,val_data,val_labels,learning_rate,batch_size,epochs, patience=15, factor=0.2):\n","  flag_start_again = 0\n","  while(flag_start_again != 2):\n","    flag_start_again = 0\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    loss_func = torch.nn.L1Loss()\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=patience, factor=factor, verbose=True)\n","\n","    losses, epoch_lst, train_accs, val_accs  = [], [] ,[], []\n","    length_train = np.shape(train_data)[0]\n","    length_val = np.shape(val_data)[0]\n","\n","    best_val_acc = 0\n","    flagy = 0\n","    for j in range(epochs):\n","        if flagy == 1 or flag_start_again == 1:\n","          break\n","        perm = np.random.permutation(length_train)\n","        train_data = train_data[perm]\n","        train_labels = train_labels[perm]\n","\n","        for i in range(0, length_train, batch_size):\n","            if (i + batch_size) > length_train:\n","                break\n","            y_in = train_data[i:i+batch_size,:]\n","            labels_in = train_labels[i:i+batch_size,:]\n","            y_in = torch.Tensor(y_in)\n","            labels_in = torch.Tensor(labels_in).long()\n","            labels_in = labels_in.float()\n","\n","            output = model(y_in)\n","            loss = loss_func(output, labels_in)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        losses.append(float(loss)/batch_size)  # compute *average* loss\n","        epoch_lst.append(j)\n","        train_cost = float(loss.detach().numpy())\n","        train_dist = estimate_avg_dist_Model_Arrival_Times_2(model, train_data, train_labels)\n","        val_dist = estimate_avg_dist_Model_Arrival_Times_2(model, val_data, val_labels)\n","        train_acc = accuracy_of_Model_Arrival_Times_2(model, train_data, train_labels)\n","        val_acc = accuracy_of_Model_Arrival_Times_2(model, val_data, val_labels)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        print(\"Epoch %d. [Val Avg Dist %.2f%%] [Train Avg Dist %.2f%%] [Val Acc %.2f%% ] [Train Acc %.2f%%, Loss %f]\" % (\n","        j, val_dist, train_dist, val_acc, train_acc, train_cost))\n","\n","        scheduler.step(val_acc)\n","        for param_group in optimizer.param_groups:\n","            curr_lr = param_group['lr']\n","        if curr_lr == learning_rate*np.power(factor,3):\n","            print(\"Training stopped. No improvement in validation accuracy for %d epochs.\" % patience)\n","            flagy = 1\n","            flag_start_again = 2\n","            break\n","\n","        if j == 10 and val_acc < 30:\n","          flag_start_again = 1\n","\n","  del y_in\n","  del labels_in\n","  return losses, epoch_lst, train_accs, val_accs\n","\n","def accuracy_of_Model_Arrival_Times_2(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    success_mask = abs_diff < success_marg\n","    success = success_mask.sum().item()\n","    all = success_mask.numel()\n","\n","    return 100 * success / all\n","\n","def distance_histogram_2(model, data, labels):\n","\n","  num = WL_trigger_middle\n","  distance_lst = np.zeros(num)\n","  count_lst = np.zeros(num)\n","  for i in range(np.shape(data)[0]):\n","    # get a batch of data\n","    y_in = data[i,:]\n","    labels_in = labels[i,:]\n","    y_in = torch.Tensor(y_in)\n","    out = model(y_in)\n","    distance_lst[int(labels_in[0])] += abs(out[0] - labels_in[0])\n","    count_lst[int(labels_in[0])] += 1\n","    distance_lst[int(labels_in[1])] += abs(out[1] - labels_in[1])\n","    count_lst[int(labels_in[1])] += 1\n","  for j in range(num):\n","    if count_lst[j] == 0:\n","      count_lst[j] = 1\n","  pyplot.figure()\n","  pyplot.scatter(np.arange(num),(distance_lst/count_lst))\n","  pyplot.show()\n","\n","\n","def estimate_avg_dist_Model_Arrival_Times_2(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    avg_dist = abs_diff.sum(dim=1).mean().item()\n","\n","    return avg_dist\n","\n","\n","def run_Model_Arrival_Times_2(labels_train,data_train,labels_val,data_val,labels_test,data_test,path1,path2, learning_rate=1e-3, batch_size=50, epochs=100):\n","  model = Model_Arrival_Times_2()\n","\n","  mu, sigma = find_normal_parameters(data_train)\n","  norm_train,norm_val,norm_test = normalize_datasets(data_train,data_val,data_test,mu,sigma)\n","\n","  learning_curve_info = train_Model_Arrival_Times_2(model,norm_train\n","                                                   , labels_train, norm_val\n","                                                   , labels_val, learning_rate, batch_size, epochs)\n","\n","  plot_learning_curve(*learning_curve_info)\n","  test_accuracy = accuracy_of_Model_Arrival_Times_2(model, norm_test, labels_test)\n","  print(\"[Test Acc %.2f%%]\" % (test_accuracy))\n","\n","  torch.save(model, path1)\n","  np.save(path2,np.array([mu,sigma,learning_rate,batch_size,epochs]))\n","  return\n","\n","class Model_Arrival_Times_1(nn.Module):\n","  def __init__(self,dim=(WL_trigger)):\n","    super().__init__()\n","    self.fc1 = nn.Linear(WL_trigger,model_NP_layer1)\n","    self.fc2 = nn.Linear(model_NP_layer1,model_NP_layer2)\n","    self.fc3 = nn.Linear(model_NP_layer2,model_NP_layer3)\n","    self.fc4 = nn.Linear(model_NP_layer3,model_NP_layer4)\n","    self.fc5 = nn.Linear(model_NP_layer4,model_P1_layer5)\n","    self.fc6 = nn.Linear(model_P1_layer5,model_P1_layer6)\n","\n","  def forward(self,x):\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.fc2(x)\n","    x = F.relu(x)\n","    x = self.fc3(x)\n","    x = F.relu(x)\n","    x = self.fc4(x)\n","    x = F.relu(x)\n","    x = self.fc5(x)\n","    x = F.relu(x)\n","    x = self.fc6(x)\n","    x = F.sigmoid(x)\n","    x = WL_trigger_middle*x\n","\n","    return x\n","\n","def train_Model_Arrival_Times_1(model,train_data,train_labels,val_data,val_labels,learning_rate,batch_size,epochs, patience=15, factor=0.2):\n","\n","  flag_start_again = 0\n","  while(flag_start_again != 2):\n","    flag_start_again = 0\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    loss_func = torch.nn.L1Loss()\n","\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=patience, factor=factor, verbose=True)\n","\n","    losses, epoch_lst, train_accs, val_accs  = [], [] ,[], []\n","    length_train = np.shape(train_data)[0]\n","    length_val = np.shape(val_data)[0]\n","\n","    best_val_acc = 0\n","    flagy = 0\n","    for j in range(epochs):\n","        if flagy == 1 or flag_start_again == 1:\n","          break\n","\n","        perm = np.random.permutation(length_train)\n","        train_data = train_data[perm]\n","        train_labels = train_labels[perm]\n","\n","        for i in range(0, length_train, batch_size):\n","            if (i + batch_size) > length_train:\n","                break\n","            y_in = train_data[i:i+batch_size,:]\n","            labels_in = train_labels[i:i+batch_size]\n","            y_in = torch.Tensor(y_in)\n","            labels_in = torch.Tensor(labels_in)\n","            labels_in = labels_in.float()\n","            labels_in = labels_in[:,None]\n","\n","            output = model(y_in)\n","            loss = loss_func(output, labels_in)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        losses.append(float(loss)/batch_size)  # compute *average* loss\n","        epoch_lst.append(j)\n","        train_cost = float(loss.detach().numpy())\n","        train_dist = estimate_avg_dist_Model_Arrival_Times_1(model, train_data, train_labels)\n","        val_dist = estimate_avg_dist_Model_Arrival_Times_1(model, val_data, val_labels)\n","        train_acc = accuracy_of_Model_Arrival_Times_1(model, train_data, train_labels)\n","        val_acc = accuracy_of_Model_Arrival_Times_1(model, val_data, val_labels)\n","        train_accs.append(train_acc)\n","        val_accs.append(val_acc)\n","        print(\"Epoch %d. [Val Avg Dist %.2f%%] [Train Avg Dist %.2f%%] [Val Acc %.2f%% ] [Train Acc %.2f%%, Loss %f]\" % (\n","        j, val_dist, train_dist, val_acc, train_acc, train_cost))\n","        scheduler.step(val_acc)\n","        for param_group in optimizer.param_groups:\n","            curr_lr = param_group['lr']\n","        if curr_lr == learning_rate*np.power(factor,3):\n","            print(\"Training stopped. No improvement in validation accuracy for %d epochs.\" % patience)\n","            flagy = 1\n","            flag_start_again = 2\n","            break\n","\n","        if j == 10 and val_acc < 30:\n","          flag_start_again = 1\n","\n","  del y_in\n","  del labels_in\n","  return losses, epoch_lst, train_accs, val_accs\n","\n","def accuracy_of_Model_Arrival_Times_1(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    labels = labels.float()\n","    labels = labels[:,None]\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    success_mask = abs_diff < success_marg\n","    success = success_mask.sum().item()\n","    all = success_mask.numel()\n","\n","    return 100 * success / all\n","\n","def distance_histogram_1(model, data, labels):\n","\n","  num = WL_trigger_middle\n","  distance_lst = np.zeros(num)\n","  count_lst = np.zeros(num)\n","  for i in range(np.shape(data)[0]):\n","    # get a batch of data\n","    y_in = data[i,:]\n","    labels_in = labels[i]\n","    labels_in = labels_in.float()\n","    labels_in = labels_in[:,None]\n","    y_in = torch.Tensor(y_in)\n","    out = model(y_in)\n","    distance_lst[int(labels_in[0])] += abs(out[0] - labels_in[0])\n","    count_lst[int(labels_in[0])] += 1\n","  for j in range(num):\n","    if count_lst[j] == 0:\n","      count_lst[j] = 1\n","  pyplot.figure()\n","  pyplot.scatter(np.arange(num),(distance_lst/count_lst))\n","  pyplot.show()\n","\n","\n","def estimate_avg_dist_Model_Arrival_Times_1(model, data, labels):\n","    data = torch.Tensor(data)\n","    labels = torch.Tensor(labels)\n","    labels = labels.float()\n","    labels = labels[:,None]\n","    out = model(data)\n","    abs_diff = torch.abs(out - labels)\n","    avg_dist = abs_diff.sum(dim=1).mean().item()\n","\n","    return avg_dist\n","\n","\n","def run_Model_Arrival_Times_1(labels_train,data_train,labels_val,data_val,labels_test,data_test,path1,path2, learning_rate=1e-3, batch_size=50, epochs=100):\n","  model = Model_Arrival_Times_1()\n","\n","  mu, sigma = find_normal_parameters(data_train)\n","  norm_train,norm_val,norm_test = normalize_datasets(data_train,data_val,data_test,mu,sigma)\n","\n","  learning_curve_info = train_Model_Arrival_Times_1(model,norm_train\n","                                                   , labels_train, norm_val\n","                                                   , labels_val, learning_rate, batch_size, epochs)\n","\n","  plot_learning_curve(*learning_curve_info)\n","  test_accuracy = accuracy_of_Model_Arrival_Times_1(model, norm_test, labels_test)\n","  print(\"[Test Acc %.2f%%]\" % (test_accuracy))\n","\n","  torch.save(model, path1)\n","  np.save(path2,np.array([mu,sigma,learning_rate,batch_size,epochs]))\n","  return"]}]}